---
title: "analysis"
author: "Eirini Zormpa"
date: "09/03/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r packages}
# install what you don't have
# install.packages("rio")
# install.packages("here")
# install.packages("readr")
# install.packages("dplyr")
# install.packages("magrittr")
# install.packages("ggplot2")

library(rio)
library(here)
library(dplyr)
library(readr)
library(magrittr)
library(ggplot2)
```

```{r read_local_annotations}
# read in data
name_onsets_local <- read_delim(here("Data", "Raw", "Naming","AH_NamingOnsets.txt"), delim = "\t") %>%
  select(-offset) %>%
  rename(praat_label = label)
```

```{r read_osf_annotations}
name_onsets <- rio::import("https://osf.io/mvtra/download", "txt") %>%
  select(-offset) %>%
  rename(praat_label = label)
```


```{r clean_annotations}
# Keep only the aloud items (42*64 = 2688) and get rid of unnecessary lines from praat annotation (time before and after word).
# The silent items have no onset and the two chunks with the condition and comments are not useful to me.
aloud_onsets <- filter(name_onsets, Response_type == "aloud")  %>%
  filter(as.character(praat_label) == as.character(Dutch_name))

# Sanity check (same number of aloud trials from all participants)
sanity_check <- aloud_onsets %>%
  group_by(Subject) %>%
  summarise(no_rows = length(Subject))

sanity_check$no_rows
```

```{r read_local_naming_data}
header = c("Subject","NamingTrial","ID","Probe_type","Stimulus_type","Response_type","File_name","English_name","Dutch_name","Other_A","Other_B","List", "Compound", "Agreement_percentage", "DK_percentage", "Lg10WF", "Familiarity", "Visual_complexity", "Manipulability", "Letters", "Non-word", "CorrectName", "Response")

filelist = list.files(path = here("Data", "Raw", "Naming", "Logfiles"), pattern = ".*.txt")

naming <- read_delim(here("Data", "Raw", "Naming", "Logfiles", filelist[1]), delim="\t", col_names = header, locale = locale("nl"), skip = 1)

for (i in 2:length(filelist)){
  naming2 <- read_delim(here("AHa", "Data", "Raw", "Naming", "Logfiles", filelist[i]), delim="\t", col_names = header, locale = locale("nl"), skip = 1)
  naming <- merge(naming, naming2, all = T)
}

rm(naming2)
```

```{r read_osf_naming_data}
naming <- rio::import("https://osf.io/3rv5f/download", "txt")
```

```{r clean_naming_data}
naming %<>% 
  select (Subject, ID, Probe_type, Stimulus_type, Response_type, English_name, Dutch_name, CorrectName) %>%
  arrange(Subject, Dutch_name)
```

```{r naming_accuracy}
nam_acc <- mean(naming$CorrectName)
  
#Check how accurate individual participants are with naming
NamAccuracy_cond <- summarise(group_by(naming, Subject, Stimulus_type, Response_type),
                              mean_correct = mean(CorrectName))

ggplot(NamAccuracy_cond)+
  geom_point(aes(x=mean_correct,y=paste(Response_type,Stimulus_type)))+
  facet_wrap(~Subject)
```

```{r join_naming_datasets}
# To join the timing onsets with the aloud items first separate aloud and silent items from naming data
aloud <- naming %>%
  filter(Response_type == "aloud")

silent <- naming %>%
  filter(Response_type == "silent")

# Filtering out incorrect trials
aloud_all <- inner_join(aloud_onsets, aloud, by = c("Subject", "Dutch_name", "Stimulus_type", "Response_type"))%>%
  select(-onset) %>%
  rename(onset = Real_onset) %>%
  mutate(onset = onset - 800)

aloud_correct <- aloud_all %>% filter(CorrectName == 1)
```

```{r visualise_naming_onsets_picture}
Picture_onsets_sub <- aloud_correct %>%
  filter(Stimulus_type == "picture") %>%
  group_by(Subject) %>%
  summarise(mean_RT=mean(onset)) %>%
  arrange(Subject)

ggplot() +
  geom_histogram(binwidth = 15, aes(x=mean_RT),data=Picture_onsets_sub)

Picture_onsets_trial <- aloud_correct %>%
  filter(Stimulus_type == "picture")

ggplot() +
  geom_histogram(binwidth = 20, aes(x=onset),data=Picture_onsets_trial)+
  facet_wrap(~Subject)
```

```{r check_outliers_picture}
# Participant 33 seems slower than the rest with a right-tailed distribution and is excluded
lat_33 <- aloud_correct %>% filter(Subject=="AH33")

mean_33 <- summarise(lat_33, mean_RT = mean(onset), sd_RT = sd(onset))

# exclude participant 33
aloud_correct %<>% filter(Subject != "AH33")
```

```{r picture_onsets_table}
Picture_onsets_descr <- aloud_correct %>%
  filter(Stimulus_type == "picture") %>%
  summarise(mean_RT = mean(onset), sd_RT = sd(onset))
```

```{r visualise_naming_onsets_picture_word}
PicWord_onsets_sub <- aloud_correct %>%
  filter(Stimulus_type == "picture+word") %>%
  group_by(Subject) %>%
  arrange(Subject)

ggplot() +
  geom_histogram(binwidth = 15, aes(x=onset),data=PicWord_onsets_sub)

PicWords_onsets_trial <- aloud_correct %>%
  filter(Stimulus_type == "picture+word")

ggplot() +
  geom_histogram(binwidth = 20, aes(x=onset),data=PicWords_onsets_trial)+
  facet_wrap(~Subject)
```


```{r picture_word_onsets_table}
PicWord_onsets_descr <- aloud_correct %>%
  filter(Stimulus_type == "picture+word") %>%
  summarise(mean_RT = mean(onset), sd_RT = sd(onset))
```
